```{python}
import os
import torch
import torch.nn as nn
import torch.optim as optim
from PIL import Image
import matplotlib.pyplot as plt
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torch.nn.functional as F
from torch.utils.data import DataLoader, random_split
import numpy as np
from sklearn.model_selection import train_test_split
```

```{python}
if torch.backends.mps.is_available():
    device = torch.device('mps')
    device_str = 'mps'
elif torch.cuda.is_available():
    device = torch.device('cuda')
    device_str = 'cuda'
else:
    device = torch.device('cpu')
    device_str = 'cpu'

torch.set_default_device(device)
```

```{python}
imsize = 64

loader = transforms.Compose([
    transforms.Resize(imsize),
    transforms.ToTensor()
])

dataset = datasets.ImageFolder(
    root='data/ThisPersonDoesNotExist/',
    transform=loader
)

train_size = int(0.8*len(dataset))
test_size = len(dataset) - train_size

train_dataset, test_dataset = random_split(
    dataset,
    [train_size, test_size],
    generator=torch.Generator(device=device_str)
)

train_loader = DataLoader(
    train_dataset,
    batch_size=100
)

test_loader = DataLoader(
    test_dataset,
    batch_size=100
)
```

```{python}
class cnnModel(nn.Module):
    def __init__(self, h1=120, h2=84, out_features=2):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 8, 3) # 8*62*62
        self.pool = nn.MaxPool2d(2, 2) # 8*31*31
        self.conv2 = nn.Conv2d(8, 32, 3) # 32*29*29
        self.fc1 = nn.Linear(32*14*14, h1)
        self.fc2 = nn.Linear(h1, h2)
        self.out = nn.Linear(h2, out_features)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.out(x)
        return x
```

```{python}
torch.manual_seed(2687)
cnn = cnnModel()
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)
```

```{python}
epochs = 2
train_losses = []
test_losses = []
train_correct = []
test_correct = []
for i in range(epochs):
    train_cr = 0
    test_cr = 0

    for j, (X_train, y_train) in enumerate(train_loader):
        X_train = X_train.to(device)
        y_train = y_train.to(device)
        j += 1
        y_pred = cnn.forward(X_train)
        loss = criterion(y_pred, y_train)

        predicted = torch.max(y_pred.data, 1)[1]
        batch_cr = (predicted == y_train).sum()
        train_cr += batch_cr

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (j+1) % 10 == 0:
            print(f'Epoch: {i+1}  Batch: {j+1}  Loss: {loss.item()}')
    
    train_losses.append(loss)
    train_correct.append(train_cr)

    with torch.no_grad():
        for j, (X_test, y_test) in enumerate(test_loader):
            X_test = X_test.to(device)
            y_test = y_test.to(device)
            y_val = cnn.forward(X_test)
            predicted = torch.max(y_val.data, 1)[1]
            test_cr += (predicted == y_test).sum()

    loss = criterion(y_val, y_test)
    test_losses.append(loss)
    test_correct.append(test_cr)
```

```{python}
```

```{python}
with torch.no_grad():
    y_eval = cnn.forward(X_test)
    loss = criterion(y_eval, y_test)

loss
```