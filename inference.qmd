```{python}
import modules.models as models
import modules.functions as func
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from PIL import Image
import torch
import torchvision
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
```

```{python}
device = func.set_device()
cnn = models.resnetModel_128()
model_dir = 'trained_models/resnetModel_128_epoch_2.pt'
cnn.load_state_dict(torch.load(model_dir, map_location=device))
cnn.eval()
imsize = 128
classes = ('Female', 'Male')
```

```{python}
loader = transforms.Compose([
    transforms.Resize([imsize, imsize]),
    transforms.Grayscale(1),
    transforms.ToTensor(),
    transforms.Normalize(0, 1)
])

my_dataset = datasets.ImageFolder(
    root='data/Validation/',
    transform=loader
)

tpdne_dataset = datasets.ImageFolder(
    root='data/ThisPersonDoesNotExist/',
    transform=loader
)

kaggle_dataset = datasets.ImageFolder(
    root='data/kaggle_faces/',
    transform=loader
)

n_images = 100

my_dataset_loader = DataLoader(
    my_dataset,
    batch_size=n_images,
    generator=torch.Generator(device=device)
)

tpdne_dataset_loader = DataLoader(
    tpdne_dataset,
    batch_size=n_images,
    generator=torch.Generator(device=device)
)

kaggle_dataset_loader = DataLoader(
    kaggle_dataset,
    batch_size=n_images,
    generator=torch.Generator(device=device)
)

data = [
    [my_dataset, my_dataset_loader],
    [tpdne_dataset, tpdne_dataset_loader],
    [kaggle_dataset, kaggle_dataset_loader]
]
```

```{python}
ds_accuracy = []
for ds in data:
    correct = 0
    with torch.no_grad():
        for i, (X, y) in enumerate(ds[1]):
            print(f'Batch {i+1}/{len(ds[1])}')

            X = X.to(device)
            y_pred = cnn.forward(X)

            predicted = torch.max(y_pred.data, 1)[1]
            batch_correct = (predicted == y).sum()
            correct += batch_correct

    accuracy = correct/len(ds[0])
    ds_accuracy.append(accuracy.item())
    
print(ds_accuracy)
```

```{python}
with torch.no_grad():
    for i, (X, y) in enumerate(tpdne_dataset_loader):
        X = X.to(device)
        y_pred = cnn.forward(X)

        predicted = torch.max(y_pred.data,1)[1]

        for j in range(len(X)):
            if predicted[j] != y[j]:
                func.imshow(X[j])
                print(f'Prediction: {classes[predicted[j]]}')
                print(f'Actual: {classes[y[j]]}')
                print(f'{classes[0]} weight: {y_pred[j][0]}')
                print(f'{classes[1]} weight: {y_pred[j][1]}\n')
```

```{python}
ext_correct = (y_pred == labels).sum().item()
ext_incorrect = (y_pred != labels).sum().item()
print(f'Correct predictions: {ext_correct}')
print(f'Incorrect predictions: {ext_incorrect}')
print(f'Accurary: {ext_correct/(ext_correct+ext_incorrect)}')
```

```{python}
cm = confusion_matrix(labels.cpu(), y_pred.cpu())
ConfusionMatrixDisplay(cm).plot()
```

```{python}
dataiter = iter(my_dataset_loader)
images, labels = next(dataiter)
with torch.no_grad():
    layer_1 = cnn.conv_1(images[3].to(device).unsqueeze(0))
    layer_2 = cnn.res_1(layer_1) + layer_1
    layer_3 = cnn.conv_2(layer_2)
    layer_4 = cnn.res_2(layer_3) + layer_3
    layer_5 = cnn.conv_3(layer_4)
    layer_6 = cnn.res_3(layer_5) + layer_5
    layer_7 = cnn.conv_4(layer_6)
    layer_8 = cnn.res_4(layer_7) + layer_7
func.imshow(torchvision.utils.make_grid(layer_1.squeeze(0).unsqueeze(1)[4]))
func.imshow(torchvision.utils.make_grid(layer_2.squeeze(0).unsqueeze(1)[4]))
func.imshow(torchvision.utils.make_grid(layer_3.squeeze(0).unsqueeze(1)[4]))
func.imshow(torchvision.utils.make_grid(layer_4.squeeze(0).unsqueeze(1)[4]))
func.imshow(torchvision.utils.make_grid(layer_5.squeeze(0).unsqueeze(1)[4]))
func.imshow(torchvision.utils.make_grid(layer_6.squeeze(0).unsqueeze(1)[4]))
func.imshow(torchvision.utils.make_grid(layer_7.squeeze(0).unsqueeze(1)[4]))
func.imshow(torchvision.utils.make_grid(layer_8.squeeze(0).unsqueeze(1)[4]))
```