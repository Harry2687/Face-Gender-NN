```{python}
import modules.models as models
import modules.functions as func
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from PIL import Image
import torch
import torchvision
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
```

```{python}
device = func.set_device()
cnn = models.resnetModel_128()
model_dir = 'trained_models/resnetModel_128_epoch_2.pt'
cnn.load_state_dict(torch.load(model_dir, map_location=device))
cnn.eval()
imsize = 128
classes = ('Female', 'Male')
n_images = 100
```

```{python}
loader = transforms.Compose([
    transforms.Resize([imsize, imsize]),
    transforms.Grayscale(1),
    transforms.ToTensor(),
    transforms.Normalize(0, 1)
])

my_dataset = datasets.ImageFolder(
    root='data/custom_test_images/',
    transform=loader
)

tpdne_dataset = datasets.ImageFolder(
    root='data/ThisPersonDoesNotExist_resize/',
    transform=loader
)

my_dataset_loader = DataLoader(
    my_dataset,
    batch_size=n_images,
    generator=torch.Generator(device=device)
)

tpdne_dataset_loader = DataLoader(
    tpdne_dataset,
    batch_size=n_images,
    generator=torch.Generator(device=device)
)

data = [
    [my_dataset, my_dataset_loader],
    [tpdne_dataset, tpdne_dataset_loader]
]
```

```{python}
ds_accuracy = []
for ds in data:
    correct = 0
    with torch.no_grad():
        for i, (X, y) in enumerate(ds[1]):
            print(f'Batch {i+1}/{len(ds[1])}')

            X = X.to(device)
            y_pred = cnn.forward(X)

            predicted = torch.max(y_pred.data, 1)[1]
            batch_correct = (predicted == y).sum()
            correct += batch_correct

    accuracy = correct/len(ds[0])
    ds_accuracy.append(accuracy.item())
    
print(ds_accuracy)
```

```{python}
y_all = torch.empty([0])
predicted_all = torch.empty([0])
with torch.no_grad():
    for i, (X, y) in enumerate(tpdne_dataset_loader):
        print(f'Batch {i+1}/{len(tpdne_dataset_loader)}')

        X = X.to(device)
        y_pred = cnn.forward(X)

        predicted = torch.max(y_pred.data,1)[1]

        y_all = torch.cat((y_all, y))
        predicted_all = torch.cat((predicted_all, predicted))

cm = confusion_matrix(y_all.cpu(), predicted_all.cpu())
ConfusionMatrixDisplay(cm).plot()
```

```{python}
with torch.no_grad():
    for i, (X, y) in enumerate(tpdne_dataset_loader):
        X = X.to(device)
        y_pred = cnn.forward(X)

        predicted = torch.max(y_pred.data,1)[1]

        for j in range(len(X)):
            if predicted[j] != y[j]:
                func.imshow(X[j])
                print(f'Prediction: {classes[predicted[j]]}')
                print(f'Actual: {classes[y[j]]}')
                print(f'{classes[0]} weight: {y_pred[j][0]}')
                print(f'{classes[1]} weight: {y_pred[j][1]}\n')
```

```{python}
dataiter = iter(my_dataset_loader)
images, labels = next(dataiter)

index = 15
image = images[index]
y_pred = cnn.forward(images.to(device))
predicted = torch.max(y_pred.data,1)[1][index]

with torch.no_grad():
    layer_1 = cnn.conv_1(image.to(device).unsqueeze(0))
    layer_2 = cnn.res_1(layer_1) + layer_1
    layer_3 = cnn.conv_2(layer_2)
    layer_4 = cnn.res_2(layer_3) + layer_3
    layer_5 = cnn.conv_3(layer_4)
    layer_6 = cnn.res_3(layer_5) + layer_5
    layer_7 = cnn.conv_4(layer_6)
    layer_8 = cnn.res_4(layer_7) + layer_7

func.imshow(image)
func.imshow(
    torchvision.utils.make_grid(
        layer_1.squeeze(0).unsqueeze(1),
        nrow=int(64**0.5)
    )
)
func.imshow(
    torchvision.utils.make_grid(
        layer_2.squeeze(0).unsqueeze(1),
        nrow=int(64**0.5)
    )
)
func.imshow(
    torchvision.utils.make_grid(
        layer_3.squeeze(0).unsqueeze(1),
        nrow=int(256**0.5)
    )
)
func.imshow(
    torchvision.utils.make_grid(
        layer_4.squeeze(0).unsqueeze(1),
        nrow=int(256**0.5)
    )
)
func.imshow(
    torchvision.utils.make_grid(
        layer_5.squeeze(0).unsqueeze(1),
        nrow=int(512**0.5)
    )
)
func.imshow(
    torchvision.utils.make_grid(
        layer_6.squeeze(0).unsqueeze(1),
        nrow=int(512**0.5)
    )
)
func.imshow(
    torchvision.utils.make_grid(
        layer_7.squeeze(0).unsqueeze(1),
        nrow=int(1024**0.5)
    )
)
func.imshow(
    torchvision.utils.make_grid(
        layer_8.squeeze(0).unsqueeze(1),
        nrow=int(1024**0.5)
    )
)
print(f'Prediction: {classes[predicted]}')
print(f'Actual: {classes[labels[index]]}')
print(f'{classes[0]} weight: {y_pred[index][0]}')
print(f'{classes[1]} weight: {y_pred[index][1]}')
```