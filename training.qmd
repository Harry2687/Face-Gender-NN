Import stuff.

```{python}
import random
import time
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
import torchvision.datasets as datasets

import modules.models as models
import modules.functions as func
```

Set device.

```{python}
device = func.set_device()
```

Load train and test iterable using datasets.CelebA.

```{python}
imsize = int(128/0.8)
batch_size = 10

fivecrop_transform = transforms.Compose([
    transforms.Resize([imsize, imsize]),
    transforms.Grayscale(1),
    transforms.FiveCrop(int(imsize*0.8)),
    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),
    transforms.Normalize(0, 1)
])

test_loader = transforms.Compose([
    transforms.Resize([int(imsize*0.8), int(imsize*0.8)]),
    transforms.Grayscale(1),
    transforms.ToTensor(),
    transforms.Normalize(0, 1)
])

train_dataset = datasets.CelebA(
    root = './data',
    split='all',
    target_type='attr',
    transform=fivecrop_transform,
    download=True
)

test_dataset = datasets.ImageFolder(
    root='data/ThisPersonDoesNotExist_resize/',
    transform=test_loader
)

train_loader = DataLoader(
    train_dataset,
    batch_size=batch_size,
    shuffle=True,
    generator=torch.Generator(device=device)
)

test_loader = DataLoader(
    test_dataset,
    batch_size=batch_size,
    shuffle=True,
    generator=torch.Generator(device=device)
)
```

Show random image with factors.

```{python}
factor = func.attributes.index('Male')
classes = ('Not ' + func.attributes[factor], func.attributes[factor])

dataiter = iter(train_loader)
images, labels = next(dataiter)

rand_num = random.randint(0, batch_size-1)

func.imshow(torchvision.utils.make_grid(images[rand_num]))
print('Selected factor:')
print(classes[labels[:, factor][rand_num]])
print('\nAll factors:')
for i, value in enumerate(labels[rand_num]):
    if value.item() == 1:
        print(func.attributes[i])
```

Set model and other stuff.

```{python}
torch.manual_seed(2687)
cnn = models.resnetModel_128()
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(
    cnn.parameters(), 
    lr=0.01,
    momentum=0.9,
    weight_decay=0.001
)
scheduler = torch.optim.lr_scheduler.StepLR(
    optimizer=optimizer,
    step_size=1,
    gamma=0.1
)
```

Train for a specified number of epochs

```{python}
epochs = 2
train_losses = []
test_losses = []
train_accuracy = []
test_accuracy = []
for i in range(epochs):
    epoch_time = 0

    for j, (X_train, y_train) in enumerate(train_loader):
        batch_start = time.time()

        X_train = X_train.to(device)
        y_train = y_train[:, factor]

        bs, ncrops, c, h, w = X_train.size()
        y_pred_crops = cnn.forward(X_train.view(-1, c, h, w))
        y_pred = y_pred_crops.view(bs, ncrops, -1).mean(1)

        loss = criterion(y_pred, y_train)

        predicted = torch.max(y_pred.data, 1)[1]
        train_batch_accuracy = (predicted == y_train).sum()/len(X_train)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_losses.append(loss.item())
        train_accuracy.append(train_batch_accuracy.item())

        batch_end = time.time()

        batch_time = batch_end - batch_start
        epoch_time += batch_time
        avg_batch_time = epoch_time/(j+1)
        batches_remaining = len(train_loader)-(j+1)
        epoch_mins_remaining = round(batches_remaining*avg_batch_time/60)
        epoch_time_remaining = func.mins_to_hours(epoch_mins_remaining)

        full_epoch = avg_batch_time*len(train_loader)
        epochs_remaining = epochs-(i+1)
        rem_epoch_mins_remaining = epoch_mins_remaining+round(full_epoch*epochs_remaining/60)
        rem_epoch_time_remaining = func.mins_to_hours(rem_epoch_mins_remaining)
        
        if (j+1) % 10 == 0:
            print(f'\nEpoch: {i+1}/{epochs} | Train Batch: {j+1}/{len(train_loader)}')
            print(f'Current epoch: {epoch_time_remaining[0]} hours {epoch_time_remaining[1]} minutes')
            print(f'Remaining epochs: {rem_epoch_time_remaining[0]} hours {rem_epoch_time_remaining[1]} minutes')
            print(f'Train Loss: {loss}')
            print(f'Train Accuracy: {train_batch_accuracy}')

    with torch.no_grad():
        for j, (X_test, y_test) in enumerate(test_loader):
            X_test = X_test.to(device)
            y_val = cnn.forward(X_test)
            loss = criterion(y_val, y_test)

            predicted = torch.max(y_val.data, 1)[1]
            test_batch_accuracy = (predicted == y_test).sum()/len(X_test)

            test_losses.append(loss.item())
            test_accuracy.append(test_batch_accuracy.item())
            
            if (j+1) % 10 == 0:
                print(f'\nEpoch: {i+1} | Test Batch: {j+1}')
                print(f'Test Loss: {loss}')
                print(f'Test Accuracy: {test_batch_accuracy}')

    scheduler.step()

    trained_model_dir = 'trained_models/'
    trained_model_name = cnn.model_name + '_epoch_' + str(i+1) + '.pt'
    torch.save(
        cnn.state_dict(), 
        trained_model_dir + trained_model_name
    )
```

Graph training loss and accuracy at end of each batch.

```{python}
plt.plot(train_losses, label='Training Loss')
plt.plot(train_accuracy, label='Training Accuracy')
plt.title('Loss at each Batch')
plt.legend()
```

Graph testing loss and accuracy at end of each batch.

```{python}
plt.plot(test_losses, label='Testing Loss')
plt.plot(test_accuracy, label='Testing Accuracy')
plt.title('Loss at each Batch')
plt.legend()
```