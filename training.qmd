Import stuff.

```{python}
import os
import random
import time
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torch.nn.functional as F
from torch.utils.data import DataLoader, random_split

import modules.models as models
import modules.functions as func
```

Set device.

```{python}
device = func.set_device()
```

Load train and test iterable using datasets.CelebA.

```{python}
imsize = int(128/0.8)
batch_size = 10

fivecrop_transform = transforms.Compose([
    transforms.Resize([imsize, imsize]),
    transforms.Grayscale(1),
    transforms.FiveCrop(int(imsize*0.8)),
    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),
    # transforms.Resize([imsize, imsize]),
    transforms.Normalize(0, 1)
])

loader = transforms.Compose([
    transforms.Resize([int(imsize*0.8), int(imsize*0.8)]),
    transforms.Grayscale(1),
    transforms.ToTensor(),
    transforms.Normalize(0, 1)
])

train_dataset = datasets.CelebA(
    root = './data',
    split='all',
    target_type='attr',
    transform=fivecrop_transform,
    download=True
)

test_dataset = datasets.ImageFolder(
    root='data/ThisPersonDoesNotExist/',
    transform=loader
)

train_loader = DataLoader(
    train_dataset,
    batch_size=batch_size,
    shuffle=True,
    generator=torch.Generator(device=device)
)

test_loader = DataLoader(
    test_dataset,
    batch_size=batch_size,
    shuffle=True,
    generator=torch.Generator(device=device)
)

dataiter = iter(train_loader)
images, labels = next(dataiter)
```

Choose factor to predict.

```{python}
factor = func.attributes.index('Male')
classes = ('Not ' + func.attributes[factor], func.attributes[factor])
```

Show random image with factors.

```{python}
rand_num = random.randint(0, batch_size-1)

func.imshow(torchvision.utils.make_grid(images[rand_num]))
print('Selected factor:')
print(classes[labels[:, factor][rand_num]])
print('\nAll factors:')
for i, value in enumerate(labels[rand_num]):
    if value.item() == 1:
        print(func.attributes[i])
```

Set model and other stuff.

```{python}
torch.manual_seed(2687)
cnn = models.resnetModel_128()
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(
    cnn.parameters(), 
    lr=0.01,
    momentum=0.9,
    weight_decay=0.001
)
scheduler = torch.optim.lr_scheduler.StepLR(
    optimizer=optimizer,
    step_size=1,
    gamma=0.1
)

print(next(cnn.parameters()).device)
print(func.n_parameters(cnn))
```

Train for a specified number of epochs

```{python}
epochs = 2
train_losses = []
test_losses = []
train_correct = []
test_correct = []
for i in range(epochs):
    epoch_time = 0
    train_cr = 0
    test_cr = 0

    for j, (X_train, y_train) in enumerate(train_loader):
        batch_start = time.time()

        X_train = X_train.to(device)
        y_train = y_train[:, factor]

        bs, ncrops, c, h, w = X_train.size()
        y_pred_crops = cnn.forward(X_train.view(-1, c, h, w))
        y_pred = y_pred_crops.view(bs, ncrops, -1).mean(1)

        # y_pred = cnn.forward(X_train)

        loss = criterion(y_pred, y_train)

        predicted = torch.max(y_pred.data, 1)[1]
        train_batch_cr = (predicted == y_train).sum()
        train_cr += train_batch_cr

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        batch_end = time.time()

        batch_time = batch_end - batch_start
        epoch_time += batch_time
        avg_batch_time = epoch_time/(j+1)
        batches_remaining = len(train_loader)-(j+1)
        epoch_mins_remaining = round(batches_remaining*avg_batch_time/60)
        epoch_time_remaining = func.mins_to_hours(epoch_mins_remaining)

        full_epoch = avg_batch_time*len(train_loader)
        epochs_remaining = epochs-(i+1)
        rem_epoch_mins_remaining = epoch_mins_remaining+round(full_epoch*epochs_remaining/60)
        rem_epoch_time_remaining = func.mins_to_hours(rem_epoch_mins_remaining)
        
        if (j+1) % 10 == 0:
            print(f'\nEpoch: {i+1} | Train Batch: {j+1}')
            print(f'Current epoch: {epoch_time_remaining[0]} hours {epoch_time_remaining[1]} minutes')
            print(f'Remaining epochs: {rem_epoch_time_remaining[0]} hours {rem_epoch_time_remaining[1]} minutes')
            print(f'Train Loss: {loss.item()}')
            print(f'Train Accuracy: {train_batch_cr/len(X_train)}')

    train_losses.append(loss.item())
    train_correct.append(train_cr.item())

    with torch.no_grad():
        for j, (X_test, y_test) in enumerate(test_loader):
            X_test = X_test.to(device)
            y_val = cnn.forward(X_test)
            loss = criterion(y_val, y_test)

            predicted = torch.max(y_val.data, 1)[1]
            test_batch_cr = (predicted == y_test).sum()
            test_cr += test_batch_cr
            
            if (j+1) % 10 == 0:
                print(f'\nEpoch: {i+1} | Test Batch: {j+1}')
                print(f'Test Loss: {loss.item()}')
                print(f'Test Accuracy: {test_batch_cr/len(X_test)}')

    scheduler.step()

    test_losses.append(loss.item())
    test_correct.append(test_cr.item())

    trained_model_dir = 'trained_models/'
    trained_model_name = cnn.model_name + '_epoch_' + str(i+1) + '.pt'
    torch.save(
        cnn.state_dict(), 
        trained_model_dir + trained_model_name
    )
```

Graph loss at the end of each epoch.

```{python}
plt.plot(train_losses, label="Training Loss")
plt.plot(test_losses, label="Validation Loss")
plt.title("Loss at Epoch")
plt.legend()
```

Graph accuracy of each epoch.

```{python}
train_size = len(train_dataset)
test_size = len(test_dataset)

plt.plot([t/train_size for t in train_correct], label="Training Accuracy")
plt.plot([t/test_size for t in test_correct], label="Validation Accuracy")
plt.title("Accuracy at the end of each Epoch")
plt.legend()
```